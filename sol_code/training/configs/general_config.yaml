model_id: "general-assistant"
description: "Model fine-tuned as a general-purpose assistant"
base_model_path: "models/base/llama-3.2-3b-base"
output_dir: "models/variants/general-assistant"
dataset_path: "data/processed/general_instruction.json"
format_type: "chat"
batch_size: 1
gradient_accumulation: 8
learning_rate: 1e-5
epochs: 3
max_length: 512 